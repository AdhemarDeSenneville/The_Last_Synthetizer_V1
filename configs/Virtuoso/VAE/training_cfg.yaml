optimizer_cfg:
  generator:
    lr: 0.0003
    betas: [0.9, 0.999]
    weight_decay: 0.0001
  discriminator:
    update_frequency: 1
    lr: 0.01
    betas: [0.9, 0.999]
    weight_decay: 0.0001

training_cfg:
  accelerator: gpu
  devices: 1
  num_nodes: 1
  precision: 32  # Float32
  deterministic: false  # Increases training speed for fixed tensor sizes
  benchmark: true  # Optimizes for fixed tensor size dataset

  # Epochs
  min_epochs: 100
  max_epochs: !!python/name:MAX_EPOCH ''
  max_time: '00:11:50:00' # For kaggle limit
  accumulate_grad_batches: 1

  # Callbacks
  callbacks:
    - EarlyStopping:
        monitor: global_loss
        patience: !!python/name:MAX_EPOCH ''
        verbose: true
        mode: min
    - ModelCheckpoint:
        monitor: train_loss
        dirpath: !!python/name:DATA_SAVE ''
        filename: best-checkpoint
        save_top_k: 1
        mode: min

  # Logging / Debug
  logger: null  # To be defined later
  profiler: simple
  fast_dev_run: !!python/name:RUN_TEST ''
  limit_train_batches: !!python/name:RUN_1_BATCH ''
  enable_checkpointing: true
  barebones: false
