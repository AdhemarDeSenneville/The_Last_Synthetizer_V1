{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_TEST = True # Do a fast run to check the pipeline is working\n",
    "RUN_1_BATCH = False # Do a fast run to check the pipeline is working\n",
    "MAX_EPOCH = 10\n",
    "\n",
    "RUN_NAME = 'TEST_1' # WandB run name\n",
    "PROJECT = 'Last_V1' # WandB project name, monitor audio outputs in real time\n",
    "HARDWARE = 'CPU' # T4 or P100 or CPU\n",
    "DATA_SAVE = 'data' # Directory to save data\n",
    "DATA_PATH = r'C:\\Users\\adhem\\Desktop\\Music\\Custom_VST\\data\\ARME-Virtuoso-Strings-2.2' # Directory to the dataset\n",
    "KAGGLE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('c:/Users/adhem/Desktop/Music/Custom_VST/code'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from launch import TrainerWarper\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cfg = {\n",
    "    'in_channels': 1,\n",
    "    'out_channels': 16,\n",
    "    'channels': [16, 32, 64, 64],\n",
    "    'factors': [4, 4, 4, 4],\n",
    "    'res_blocks': 2,\n",
    "    'activation': nn.SiLU,\n",
    "    'use_norm': True,\n",
    "    'num_groups': 4,\n",
    "    'variational': True,\n",
    "    'lstm': True,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizer Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_cfg = {\n",
    "    'lr': 0.001,\n",
    "    'betas': (0.9, 0.999),\n",
    "    'weight_decay': 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_cfg = {\n",
    "    'L1TemporalLoss':{\n",
    "        'weight':1,\n",
    "        'balancer': True,\n",
    "        'key_output': 'x_hat',\n",
    "        'key_target': 'x',\n",
    "        },\n",
    "    'L2TemporalLoss':{\n",
    "        'weight':1,\n",
    "        'balancer': True,\n",
    "        'key_output': 'x_hat',\n",
    "        'key_target': 'x',\n",
    "        },\n",
    "    'AuralossLoss':{\n",
    "        'weight':1,\n",
    "        'balancer': True,\n",
    "        'key_output': 'x_hat',\n",
    "        'key_target': 'x',\n",
    "        \"fft_sizes\": [32, 128, 512, 2048],  # [32, 128, 512, 2048, 8192, 32768]\n",
    "        \"hop_sizes\": [16, 64, 256, 1024],  # [16, 64, 256, 1024, 4096, 16384]\n",
    "        \"win_lengths\": [32, 128, 512, 2048],  # [32, 128, 512, 2048, 8192, 32768]\n",
    "        \"w_sc\": 0.0,\n",
    "        \"w_phs\": 0.0,\n",
    "        \"w_lin_mag\": 1.0,\n",
    "        \"w_log_mag\": 1.0,\n",
    "    },\n",
    "    'KLDivergenceLoss':{\n",
    "        'weight':1,\n",
    "        'balancer': False,\n",
    "        'key_mean': 'z_mean',\n",
    "        'key_log_std': 'z_log_std',\n",
    "        },\n",
    "    'Discriminator':{\n",
    "        'weight':1,\n",
    "        'balancer': True,\n",
    "        #'type':'Spectrogram_VGGStyle',\n",
    "    },\n",
    "    'FeatureLoss':{\n",
    "        'weight':1,\n",
    "        'balancer': True,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cfg = {\n",
    "    'path': DATA_PATH,\n",
    "    'sr': 22050,\n",
    "    'sample_duration':8, # Seconds\n",
    "    'latent_compression': 4**4,\n",
    "    'envelope_detector':{\n",
    "        'type': 'Max',\n",
    "        },\n",
    "    'pitch_detector': {\n",
    "        'n_fft': 4096,\n",
    "        'hop_length': 1024,\n",
    "        'fmin': 75,\n",
    "        'fmax': 800,\n",
    "        'threshold': 0.15,\n",
    "        'win_length': None,  # Defaults to n_fft\n",
    "        'window': 'hann',\n",
    "        'center': True,\n",
    "        'pad_mode': 'reflect'\n",
    "    },\n",
    "    'batch_size': 8,\n",
    "    'num_workers': 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On laptop CPU\n"
     ]
    }
   ],
   "source": [
    "if KAGGLE:\n",
    "    # Kaggle herdware\n",
    "    if HARDWARE == 'T4':\n",
    "        num_gpus = 2\n",
    "        available_devices = [0,1]\n",
    "        print('On Kaggle Double T4')\n",
    "    elif HARDWARE == 'P100':\n",
    "        num_gpus = 1\n",
    "        available_devices = [0]\n",
    "        print('On Kaggle P100')\n",
    "    else:\n",
    "        num_gpus = 0\n",
    "        available_devices = ['CPU']\n",
    "        print('On Kaggle CPU')\n",
    "else:\n",
    "    num_gpus = 0 # No gpu on my computer :(\n",
    "    available_devices = ['CPU']\n",
    "    print('On laptop CPU')\n",
    "\n",
    "accelerator = 'gpu' if num_gpus > 0 else 'cpu'\n",
    "devices = num_gpus if num_gpus > 0 else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "training_cfg = {\n",
    "    \n",
    "    # Hardware\n",
    "    'accelerator': accelerator,\n",
    "    'devices': devices,\n",
    "    'num_nodes': 1,\n",
    "    'precision': 32,  # Float32\n",
    "    'deterministic': False,  # Increases training speed for fixed tensor sizes\n",
    "    'benchmark': True,  # Optimizes for fixed tensor size dataset\n",
    "    \n",
    "    # Epochs\n",
    "    'min_epochs': 4,\n",
    "    'max_epochs': MAX_EPOCH,\n",
    "    'max_time': '00:12:00:00',\n",
    "    'accumulate_grad_batches': 1,\n",
    "    \n",
    "    # Callbacks\n",
    "    'callbacks': [\n",
    "    ('EarlyStopping', \n",
    "     {\n",
    "        'monitor': 'train_loss',\n",
    "        'patience': 5, \n",
    "        'verbose': True, \n",
    "        'mode': 'min'\n",
    "    }),\n",
    "\n",
    "    ('ModelCheckpoint', \n",
    "     {\n",
    "        'monitor': 'train_loss', \n",
    "        'dirpath': f'{DATA_SAVE}/', \n",
    "        'filename': 'best-checkpoint', \n",
    "        'save_top_k': 1, \n",
    "        'mode': 'min'\n",
    "    }),\n",
    "    ],\n",
    "    \n",
    "    # Logging / Debug\n",
    "    'logger': None,  # To be defined later\n",
    "    'profiler': 'simple',\n",
    "    'fast_dev_run': RUN_TEST,\n",
    "    'limit_train_batches': 1 if RUN_1_BATCH else None,\n",
    "    'enable_checkpointing': True,\n",
    "    'barebones': False,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "all_config = {\n",
    "    'TRAINING': training_cfg,\n",
    "    'MODEL': model_cfg,\n",
    "    'DATA': data_cfg,\n",
    "    'TRAINER': training_cfg,\n",
    "}\n",
    "\n",
    "training_cfg['logger'] = None if (RUN_TEST or RUN_1_BATCH) else WandbLogger(project=PROJECT, name=RUN_NAME, config=all_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\adhem\\anaconda3\\envs\\Audio\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\logger_connector\\logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n"
     ]
    }
   ],
   "source": [
    "TRAINER = TrainerWarper(\n",
    "    model_cfg,\n",
    "    data_cfg,\n",
    "    optimizer_cfg,\n",
    "    loss_cfg,\n",
    "    training_cfg\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name  | Type          | Params | Mode \n",
      "------------------------------------------------\n",
      "0 | model | Autoencoder1d | 506 K  | train\n",
      "------------------------------------------------\n",
      "506 K     Trainable params\n",
      "0         Non-trainable params\n",
      "506 K     Total params\n",
      "2.026     Total estimated model params size (MB)\n",
      "189       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "c:\\Users\\adhem\\anaconda3\\envs\\Audio\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:419: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] 0 torch.Size([8, 32, 513, 690])\n",
      "1 torch.Size([8, 32, 513, 345])\n",
      "2 torch.Size([8, 32, 511, 173])\n",
      "3 torch.Size([8, 32, 505, 87])\n",
      "4 torch.Size([8, 32, 503, 85])\n",
      "torch.Size([8, 501, 83])\n",
      "torch.Size([8, 81])\n",
      "0 torch.Size([8, 32, 513, 690])\n",
      "1 torch.Size([8, 32, 513, 345])\n",
      "2 torch.Size([8, 32, 511, 173])\n",
      "3 torch.Size([8, 32, 505, 87])\n",
      "4 torch.Size([8, 32, 503, 85])\n",
      "torch.Size([8, 501, 83])\n",
      "torch.Size([8, 81])\n"
     ]
    }
   ],
   "source": [
    "TRAINER.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Audio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
