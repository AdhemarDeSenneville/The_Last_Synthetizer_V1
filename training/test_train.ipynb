{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_TEST = True # Do a fast run to check the pipeline is working\n",
    "RUN_1_BATCH = False # Do a fast run to check the pipeline is working\n",
    "MAX_EPOCH = 10\n",
    "\n",
    "RUN_NAME = 'TEST_1' # WandB run name\n",
    "PROJECT = 'Last_V1' # WandB project name, monitor audio outputs in real time\n",
    "HARDWARE = 'CPU' # T4 or P100 or CPU\n",
    "DATA_SAVE = 'data' # Directory to save data\n",
    "DATA_PATH = r'C:\\Users\\adhem\\Desktop\\Music\\Custom_VST\\data\\ARME-Virtuoso-Strings-2.2' # Directory to the dataset\n",
    "KAGGLE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlaunch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TrainerWarper\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\adhem\\Desktop\\Music\\Custom_VST\\code\\training\\launch.py:2\u001b[0m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mVAE_training\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LitAutoEncoder\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AudioDataset\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Trainer\n",
      "\u001b[1;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "from launch import TrainerWarper\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cfg = {\n",
    "    'in_channels': 1,\n",
    "    'out_channels': 16,\n",
    "    'channels': [16, 32, 64, 64],\n",
    "    'factors': [4, 4, 4, 4],\n",
    "    'res_blocks': 2,\n",
    "    'activation': nn.SiLU,\n",
    "    'use_norm': True,\n",
    "    'num_groups': 4,\n",
    "    'variational': True,\n",
    "    'lstm': True,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizer Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_cfg = {\n",
    "    'lr': 0.001,\n",
    "    'betas': (0.9, 0.999),\n",
    "    'weight_decay': 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_cfg = {\n",
    "    'L1TemporalLoss':{\n",
    "        'weight':1,\n",
    "        'balancer': True,\n",
    "        'key_output': 'x_hat',\n",
    "        'key_target': 'x',\n",
    "        },\n",
    "    'L2TemporalLoss':{\n",
    "        'weight':1,\n",
    "        'balancer': True,\n",
    "        'key_output': 'x_hat',\n",
    "        'key_target': 'x',\n",
    "        },\n",
    "    'AuralossLoss':{\n",
    "        'weight':1,\n",
    "        'balancer': True,\n",
    "        'key_output': 'x_hat',\n",
    "        'key_target': 'x',\n",
    "        \"fft_sizes\": [32, 128, 512, 2048],  # [32, 128, 512, 2048, 8192, 32768]\n",
    "        \"hop_sizes\": [16, 64, 256, 1024],  # [16, 64, 256, 1024, 4096, 16384]\n",
    "        \"win_lengths\": [32, 128, 512, 2048],  # [32, 128, 512, 2048, 8192, 32768]\n",
    "        \"w_sc\": 0.0,\n",
    "        \"w_phs\": 0.0,\n",
    "        \"w_lin_mag\": 1.0,\n",
    "        \"w_log_mag\": 1.0,\n",
    "    },\n",
    "    'KLDivergenceLoss':{\n",
    "        'weight':1,\n",
    "        'balancer': False,\n",
    "        'key_mean': 'z_mean',\n",
    "        'key_log_std': 'z_log_std',\n",
    "        },\n",
    "    'Discriminator':{\n",
    "        'weight':1,\n",
    "        'balancer': True,\n",
    "        #'type':'Spectrogram_VGGStyle',\n",
    "    },\n",
    "    'FeatureLoss':{\n",
    "        'weight':1,\n",
    "        'balancer': True,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cfg = {\n",
    "    'path': DATA_PATH,\n",
    "    'sr': 22050,\n",
    "    'sample_duration':8, # Seconds\n",
    "    'latent_compression': 4**4,\n",
    "    'envelope_detector':{\n",
    "        'type': 'Max',\n",
    "        },\n",
    "    'pitch_detector': {\n",
    "        'n_fft': 4096,\n",
    "        'hop_length': 1024,\n",
    "        'fmin': 75,\n",
    "        'fmax': 800,\n",
    "        'threshold': 0.15,\n",
    "        'win_length': None,  # Defaults to n_fft\n",
    "        'window': 'hann',\n",
    "        'center': True,\n",
    "        'pad_mode': 'reflect'\n",
    "    },\n",
    "    'batch_size': 8,\n",
    "    'num_workers': 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if KAGGLE:\n",
    "    # Kaggle herdware\n",
    "    if HARDWARE == 'T4':\n",
    "        num_gpus = 2\n",
    "        available_devices = [0,1]\n",
    "        print('On Kaggle Double T4')\n",
    "    elif HARDWARE == 'P100':\n",
    "        num_gpus = 1\n",
    "        available_devices = [0]\n",
    "        print('On Kaggle P100')\n",
    "    else:\n",
    "        num_gpus = 0\n",
    "        available_devices = ['CPU']\n",
    "        print('On Kaggle CPU')\n",
    "else:\n",
    "    num_gpus = 0 # No gpu on my computer :(\n",
    "    available_devices = ['CPU']\n",
    "    print('On laptop CPU')\n",
    "\n",
    "accelerator = 'gpu' if num_gpus > 0 else 'cpu'\n",
    "devices = num_gpus if num_gpus > 0 else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "training_cfg = {\n",
    "    \n",
    "    # Hardware\n",
    "    'accelerator': accelerator,\n",
    "    'devices': devices,\n",
    "    'num_nodes': 1,\n",
    "    'precision': 32,  # Float32\n",
    "    'deterministic': False,  # Increases training speed for fixed tensor sizes\n",
    "    'benchmark': True,  # Optimizes for fixed tensor size dataset\n",
    "    \n",
    "    # Epochs\n",
    "    'min_epochs': 4,\n",
    "    'max_epochs': MAX_EPOCH,\n",
    "    'max_time': '00:12:00:00',\n",
    "    'accumulate_grad_batches': 1,\n",
    "    \n",
    "    # Callbacks\n",
    "    'callbacks': [\n",
    "    ('EarlyStopping', \n",
    "     {\n",
    "        'monitor': 'train_loss',\n",
    "        'patience': 5, \n",
    "        'verbose': True, \n",
    "        'mode': 'min'\n",
    "    }),\n",
    "\n",
    "    ('ModelCheckpoint', \n",
    "     {\n",
    "        'monitor': 'train_loss', \n",
    "        'dirpath': f'{DATA_SAVE}/', \n",
    "        'filename': 'best-checkpoint', \n",
    "        'save_top_k': 1, \n",
    "        'mode': 'min'\n",
    "    }),\n",
    "    ],\n",
    "    \n",
    "    # Logging / Debug\n",
    "    'logger': None,  # To be defined later\n",
    "    'profiler': 'simple',\n",
    "    'fast_dev_run': RUN_TEST,\n",
    "    'limit_train_batches': 1 if RUN_1_BATCH else None,\n",
    "    'enable_checkpointing': True,\n",
    "    'barebones': False,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "all_config = {\n",
    "    'TRAINING': training_cfg,\n",
    "    'MODEL': model_cfg,\n",
    "    'DATA': data_cfg,\n",
    "    'TRAINER': training_cfg,\n",
    "}\n",
    "\n",
    "training_cfg['logger'] = None if (RUN_TEST or RUN_1_BATCH) else WandbLogger(project=PROJECT, name=RUN_NAME, config=all_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainerWarper(\n",
    "    model_cfg,\n",
    "    data_cfg,\n",
    "    optimizer_cfg,\n",
    "    loss_cfg,\n",
    "    training_cfg,):\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Audio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
